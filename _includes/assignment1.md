### Assignment 1: Group Presentation \- "Values"

Presentations will be during the lab sessions on **November 8th**. You are expected to be present for the entire lab session your group is scheduled in, not doing so may impact your grade.

Make sure to submit your presentation slides (as a PDF file) on Canvas \- not submitting the presentation may result in a failing grade.

**Objective:**

The aim of this assignment is to select and critically analyse an ML research paper\* through a human-centred lens. This exercise will involve identifying the paper's consideration of human factors, potential ethical implications, and limitations related to human interaction with the proposed ML system.

\* Not every paper will be suitable for this (e.g., a purely theoretical paper may not be suitable), consider the complete assignment when selecting the paper \- ask the teaching team in case of doubt.

A rough outline of a fitting presentation is as follows:

**Introduction (\~2 minutes)**

- Briefly introduce yourselves and the topic of your presentation.  
- Mention the specific research paper you've chosen for analysis (title, authors, publication year).  
- Briefly outline the research question and proposed ML technique of the chosen paper.

**Human-Centred Analysis (\~2 minutes)**

Discuss the paper's consideration of human factors through the following prompts:

- User-centred design: Did the paper incorporate user studies or design principles?  
- User interaction: How does the ML system interact with humans? Is there any discussion of UI/UX considerations?  
- Data and model bias: Does the paper address potential biases in the data or the model's decision making that could impact users?  
- Ethical considerations: Does the paper address ethical concerns like privacy, fairness, or transparency related to the ML system's use?

**Limitations and Human Factors (\~2 minutes)**

- Identify limitations in the paper related to human-centred aspects.  
- Consider aspects like lack of user studies, unclear outputs for users, or potential user misunderstandings.  
- Discuss how these limitations could affect the real-world implementation and user experience.

**Conclusion and Recommendations (\~1 minute)**

- Briefly summarise your analysis.  
- Present your recommendations for improving the human-centred aspects of the paper.

Following each presentation there will be a brief (2 minute) Q\&A.

**Grading Rubric:**

- Quality and relevance of chosen research paper (10%)  
- Clarity and accuracy of paper summary (15%)  
- Depth and insightfulness of human-centred analysis (30%)  
- Identification and discussion of limitations (30%)  
- Quality and feasibility of recommendations (15%)

** Suggested papers: ** 

* [VILA: Learning Image Aesthetics from User Comments with Vision-Language Pretraining.](https://openaccess.thecvf.com/content/CVPR2023/papers/Ke_VILA_Learning_Image_Aesthetics_From_User_Comments_With_Vision-Language_Pretraining_CVPR_2023_paper.pdf)
* [Automatic Discovery of Meme Genres with Diverse Appearances.](https://cdn.aaai.org/ojs/18097/18097-28-21592-1-2-20210521.pdf)
* [TIBET: Identifying and Evaluating Biases in Text-to-Image Generative Model.](https://arxiv.org/abs/2312.01261)
* [Visual Stereotypes of Autism Spectrum in DALL-E, Stable Diffusion, SDXL, and Midjourney.](https://arxiv.org/abs/2407.16292)
* [When and why vision-language models behave like bags-of-words, and what to do about it?](https://arxiv.org/abs/2210.01936)
* [CheXclusion: Fairness gaps in deep chest X-ray classifiers](https://arxiv.org/pdf/2003.00827)
* [A Workbench for Autograding Retrieve/Generate Systems](https://dl.acm.org/doi/10.1145/3626772.3657871)
* [Mechanism Design for Large Language Models](https://www2024.thewebconf.org/program/awards/)
* [PAIR Diffusion: A Comprehensive Multimodal Object-Level Image Editor](https://arxiv.org/pdf/2303.17546)
* [AutoAD: Movie Description in Context](https://openaccess.thecvf.com/content/CVPR2023/papers/Han_AutoAD_Movie_Description_in_Context_CVPR_2023_paper.pdf)
* [LLAVAGUARD: VLM-based Safeguards for Vision Dataset Curation and Safety Assessment](https://arxiv.org/abs/2406.05113)
* [Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and Prompt Engineering May Not Help You](https://arxiv.org/abs/2401.16092)
* [On Evaluating Adversarial Robustness of Large Vision-Language Models](https://arxiv.org/abs/2305.16934)
* [A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support](https://arxiv.org/abs/2009.08441)
* [RedCaps: web-curated image-text data created by the people, for the people](https://arxiv.org/abs/2111.11431)
* [Generative Agents: Interactive Simulacra of Human Behavior](https://dl.acm.org/doi/10.1145/3586183.3606763)
* [The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes](https://proceedings.neurips.cc/paper/2020/hash/1b84c4cee2b8b3d823b30e2d604b1878-Abstract.html)
* [Segment Anything](https://ieeexplore.ieee.org/document/10378323)