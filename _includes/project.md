# Project (30%)

**Submission deadline: December 16, 2024 EOD**

**Objective:**  
This project challenges you to explore the practical application of human-centred ML (HCML) techniques within the context of social good initiatives. With your group you will choose a research topic related to HCML and design an experiment to evaluate the effectiveness of a chosen technique on a dataset relevant to a social good problem. The focus will be on analysing the technique's performance and limitations from a human-centred perspective, considering its potential impact on social good efforts.

The grade of the project will be based on a presentation and oral evaluation.

**Project Setup:**

1. **Social Good Problem:**

Identify a specific social good problem you find compelling. This could relate to education, healthcare, sustainability, or any other area where ML can create a positive social impact.

2. **Research Topic Selection:**

Choose a research topic related to HCML, aligning it with your chosen social good problem. For example:

- **Active Learning:** Can be used to identify the most informative data points for human annotation in areas like medical diagnosis or disaster response.  
- **Learning from Crowdsourcing:** Useful for gathering and incorporating noisy labels from human volunteers for tasks like image classification in environmental monitoring projects.  
- **Reinforcement Learning from Human Feedback (RLHF):** Training AI assistants for social workers or educators through human-provided feedback.  
- **Semi-supervised Learning:** Combining labelled data from experts with large amounts of unlabeled data to improve models for tasks like early disease detection in healthcare.  
- **Machine Teaching**: An existing ML pipeline for a social good problem can be evaluated and analysed through (interactive) Machine Teaching.


3. **Experimental Design:**

Select a specific technique within your chosen research topic. Design an experiment to evaluate the chosen technique on a dataset relevant to your chosen social good problem. 

Compare the performance of your chosen technique against a reasonable baseline (e.g., majority voting for crowdsourcing, random acquisition for active learning).

The aim of the assignment is not to literally reproduce an existing paper. The chosen technique should not have been applied to that dataset yet (you don't have to exhaustively check all literature for this, but it should not be a typical approach for this dataset). You can choose an existing paper and use their approach as the baseline and compare it to a human-centred technique.

4. **Human-Centred Analysis:**

Analyse the results of your experiment, considering the human-centred aspects of the chosen technique in relation to your social good problem. This could involve:

- **Impact of human effort:** Evaluate the efficiency of the technique in terms of human labelling or feedback requirements, considering volunteer burden reduction in social good initiatives.  
- **Fairness and bias:** Consider potential biases in the data or the technique's impact on different user groups, ensuring equitable access to social good applications.  
- **Interpretability:** Analyse how well the technique's results can be explained to non-technical stakeholders involved in the HCML application for social good.

Discuss the potential social impact of your chosen HCML technique within the context of your social good problem. Consider how it could improve existing or contribute to new solutions.

5. **Deliverables:**  
   - Presentation slide deck with 5 slides:  
     - Title slide (with names of group members and project title)  
     - Slide on the chosen social good problem and its relevance.  
     - Slide on the experimental design, including the chosen dataset, baseline comparison, and social good context.  
     - Slide with the experimental results including comparison to baselines  
     - Summary of the findings, with a focus on human-centred aspects (efficiency, fairness, interpretability) and potential social impact.  
     - **The slidedeck should be submitted on Canvas December 16, EOD**.  
   - Oral evaluation (on December 18):  
     - In a 15 minute session you will briefly (5-7 minutes) pitch your project, using the slide deck.  
     - A Q\&A will follow your pitch focused on probing your understanding of the project and the individual contributions.

**Requirements**:

- Presentation should be submitted as a single PDF (16:9 aspect ratio).  
- Maximum 5 slides.  
- Oral presentation maximum 7 minutes.

**Grading Rubric:**

- Slides clarity (10%)  
- Pitch clarity (10%)  
- Experimental Setup and Execution (40%)  
- Accuracy and clarity during Q\&A (40%)

